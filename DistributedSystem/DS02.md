## 分布式文件系统

分布式文件系统主要有两个功能：一个是存储文档，图像，视频之类的Blob类数据；一个是作为分布式表格系统的持久化层。分布式文件系统中最著名的就是Google File System(GFS)，因此，本章通过介绍GFS的内部实现机制来学习分布式文件系统的知识与设计。

### 架构

![GFS整体架构](http://on64c9tla.bkt.clouddn.com/Comput/gfs-architecture.png)

一个GFS系统中的节点有三种角色：**GFS主控服务器(GFS Master)，GFS数据块服务器(GFS ChunkServer)和GFS客户端**。

GFS存储系统中的文件被分割成固定大小的数据块(chunk)，在chunk创建时，Master服务器给每个chunk分配一个全局唯一的chunk句柄。数据块服务器(ChunkServer,CS)把chunk以linux文件的形式存储到磁盘中，并根据指定的chunk句柄和字节范围来读写数据。为了保证可靠性，chunk在不同的服务器中复制多个副本，默认是三份。

主控服务器维护系统的元数据，包括文件，chunk命名空间，文件到chunk之间的映射关系，chunk位置信息。同时，也负责整个系统的全局控制，如chunk租约管理，垃圾回收无用的chunk，chunk复制等。主控服务器 **周期地** 与CS服务器通过 **心跳的方式** 交换信息。

客户端是GFS提供给应用程序的访问接口，它是一组专用接口，不遵循POSIX规范，以库文件的形式提供。客户端访问GFS时，首先访问主控服务器节点，获取与之交互的CS信息，然后直接访问这些CS，完成数据存取工作。值得注意的是，GFS客户端不缓存文件数据，只缓存主控服务器中获取的元数据。

### 关键问题

**租约机制**

GFS系统中通过租约机制将chunk写操作授权给ChunkServer，从而减轻Master的负载。拥有租约授权的ChunkServer称为主ChunkServer，其他副本所在的ChunkServer称为备ChunkServer。主ChunkServer可以不断向Master请求延长租约的有效期直到整个chunk写满。

**一致性模型**

GFS系统主要是为了追加(append)而不是改写(overwrite)而设计的。如果不发生异常，追加成功的记录在GFS的各个副本中是确定并且严格一致的；如果出现异常，客户端将追究重试，直至成功（所有副本中至少成功追加一次）。

**追加流程**

追加流程如下所示：

![gfs-append](http://on64c9tla.bkt.clouddn.com/Comput/gfs-append.png)

1）客户端向Master请求chunk每个副本所在的ChunkServer，其中主ChunkServer持有修改租约。如果没有ChunkServer持有租约，说明该chunk最近没有写操作，Master会发起一个任务，按照一定的策略将chunk的租约授权给其中的一台ChunkServer。

2）Master返回给客户端主副本和备副本所在的chunk的位置信息，客户端将缓存这些信息供以后使用。如果不出现故障，客户端以后读写该chunk都不需要再次请求Master。

3）客户端将追加的记录发送到每一个副本中，每一个ChunkServer会在内部的LRU结构中缓存这些数据。GFS中采用数据流和控制流分流的方法，从而能够基于网络拓扑结构更好地调度数据流的传输。

4）当所有副本都确认收到了数据，客户端发起一个写请求控制命令给主副本。由于主副本可能收到多个客户端对同一个chunk的并发追加操作，主副本将确定这些操作的顺序写入本地。

5）主副本把写请求提交给所有的副本。每一个备副本会根据主副本确定的顺序执行写操作。

6）备副本成功完成后应答主副本。

7）主副本应答客户端，如果有副本发生错误，将出现主副本写成功但某些备副本不成功的情况，客户端将重试。

GFS追加有两个特色：流水线及分离数据流和控制流。流水线操作可以减少延时。分离数据流和控制流主要为了优化数据传输，每一台机器都是把数据发送给网络拓扑图上”最近“的尚未收到数据的节点。

**容错机制**

### 基本知识点

**chunk尺寸**

GFS系统中chunk的大小是64MB。每个chunk的副本都以普通Linux文件的形式保存在CS服务器中。采用较大的chunk尺寸具有以下优点：1）可以减少客户端与主控服务器的请求次数。只需要一次与主控服务器的交互就可以获取chunk的位置信息，然后缓存到客户端，之后就可以对同一个chunk进行多次读写操作。2）因为客户端能够对一个chunk进行多次操作，客户端与数据块服务器保持较长时间的TCP连接，可以减少网络负载。3）一定程度上减少了主控服务器中需要保存的元数据的数量。

**元数据**
主控服务器存储三种主要类型的元数据：**文件和chunk命名空间，文件和chunk的映射关系，每个chunk副本的位置信息**。所有的元数据都保存在主控服务器的内存中。同时，前两种类型的元数据（文件和chunk命名空间，文件和chunk映射关系）也会以记录的方式记录在操作系统的系统日志中，并存储在持久化介质上，另外，日志会复制到其他远程的主控服务器上。这样做的目的是，提供简单的可靠性，保证主控服务器崩溃的情况下数据的一致性。

每个chunk的元数据不超过64字节。那么1PB数据的chunk元数据大小不超过1PB x 3 / 64MB x 64 = 3GB。

**chunk位置信息**

主控服务器并不持久化保存数据块服务器中的chunk信息，而是在启动时轮询数据块服务器以获取这些信息，并且周期性地通过心跳信息监控数据块服务器的状态。这样做的目的是 **在数据块服务器加入集群，离开集群，更名，失效，以及重启的时候，主控服务器可以保证与数据块服务器中chunk信息的一致性**。

**操作日志**

主控服务器在日志增长到一定量时对系统状态做一次checkpoint，将所有的状态数据写入一个checkpoint文件。在灾难恢复的时候，主控服务器通过读取磁盘上的checkpoint文件，以及重演checkpoint之后的有限个日志文件就能够恢复系统。checkpoint文件以压缩B树的数据结构存储。
